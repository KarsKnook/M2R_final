import networkx as nx
import numpy as np
import random as rand
import matplotlib.pyplot as plt
import itertools
import math
from geopy import Nominatim

# Step 0: Graph Generator
def generate_graph_triangle(n=10, a=1, b=1):
    """
    Input: n is the number of nodes we want
    [0,a] x [0,b] is the set where the nodes lie within
    Output: G is a complete weighted graph with n nodes with positions 
    randomly generated from the uniform distribution U([0, a]x[0, b])
    with weight equal to the distance between the two nodes
    the weight is a metric!
    """

    G = nx.Graph()   # create a graph

    node_labels = range(n)   # label the n nodes
    # generate the position coordinates of the nodes
    coordinates = [np.array([np.random.uniform(0, a, 1)[0], np.random.uniform(0, b, 1)[0]]) for i in node_labels]
    pos = dict(zip(node_labels, coordinates))

    # define the weight of an edge by the Euclidean distance between the two nodes
    edge_list = [(i, j, np.linalg.norm(coordinates[i] - coordinates[j])) for i in range(n) for j in range(i+1, n)] 
    G.add_weighted_edges_from(edge_list)

    return G, pos

def get_coordinates(cities):
    geolocator = Nominatim(user_agent="tabu_search_application")
    cities_coordinates = []
    
    for city in cities:
        try:
            location = geolocator.geocode(city)
            cities_coordinates.append((location.longitude, location.latitude))
        except:
            raise Exception(f"There was a problem with the coordinates of {city}")
    return cities_coordinates

def draw_solution(G, solution=[], pos=None):
    # docstring

    if not pos:
        pos = nx.circular_layout(G)  # could also choose other layouts

    nx.draw_networkx_nodes(G, pos, node_color="k", alpha=0.75)  # nx.draw(G, pos) draws all the edges

    node_list = range(G.number_of_nodes())
    node_labels = dict(zip(node_list, [f"{i}" for i in node_list]))
    nx.draw_networkx_labels(G, pos, node_labels, font_color="w")

    solution = [0] + solution + [0]
    solution_edges = [(solution[i], solution[i+1]) for i in range(len(solution) - 1)]
    nx.draw_networkx_edges(G, pos, edgelist=solution_edges, edge_color='r', width=2)

    weight_list = [G[i[0]][i[1]]['weight'] for i in solution_edges]
    weight_list_string = [str(round(i,2)) for i in weight_list]
    edge_labels = dict(zip(solution_edges, weight_list_string))
    nx.draw_networkx_edge_labels(G, pos, edge_labels, bbox=dict(alpha=0), verticalalignment="baseline", font_size=8)

    ax = plt.subplot(111)
    t = plt.text(0.01, 1.05, f"Path length: {round(sum(weight_list),2)}", transform=ax.transAxes, fontsize=15)
    t.set_bbox(dict(facecolor='red', alpha=0.5, edgecolor='red'))

    plt.show()

def roulette(initial_list):
    """
        Input: list of positive numbers.
        Output: A 2-tuple containing a random element from the Python list other than the maximum and 
        its index.
    """

    # remove the minimum of initial_list
    second_list = initial_list.copy()
    minimum = min(second_list)
    second_list.remove(minimum)

    # assign a probability distribution to all non-minimum elements in initial_list
    # the probability of getting x should be inversely proportional to x
    reciprocals = np.array([1/x for x in second_list])
    probabilities = reciprocals/np.sum(reciprocals)

    # draw x from the roulette distribution and find the index of x
    random_number = np.random.choice(second_list, p=probabilities) 
    number_index = initial_list.index(random_number)

    return random_number, number_index

def collinear(s0,s1,a = 0.01, b = 0.01, c = 0.01):
    """
    Input: two line segments s0 and s1 with endpoints [A,B], [C,D] respectively
    Output: T/F statement on whether s0, s1 (nearly) cross 
    parameters:
    For graph in [0,1]x[0,1], set a = b = c = 0.01
    These parameters can be change according the range of coordinates
    i.e. a = width_of_G * 0.01
         b = height_of_G * 0.01
         c = width_of_G * 0.01
    """

    if s0[1][0]==s0[0][0]:
        if s1[1][0] == s1[0][0]:
            gradient = [10000,10000]
        else:
            gradient = [10000, (s1[1][1] -s1[0][1])/(s1[1][0] -s1[0][0])]
    else:
        if s1[1][0] == s1[0][0]:
            gradient = [(s0[1][1] -s0[0][1])/(s0[1][0] -s0[0][0]), 10000]
        else:
            gradient = [(s0[1][1] -s0[0][1])/(s0[1][0] -s0[0][0]), (s1[1][1] -s1[0][1])/(s1[1][0] -s1[0][0])]
        
    y_intercept = [s0[0][1] - gradient[0]*s0[0][0], s1[0][1] - gradient[1]*s1[0][0]]
    x_intercept = [-y_intercept[0]/gradient[0], -y_intercept[1]/gradient[1]]

    # check if s0, s1 (nearly) colinear
    #Case 1: s0, s1 is not vertical
    if abs(gradient[0] - gradient[1]) < a and abs(y_intercept[0] - y_intercept[1]) < b:
        return (max(s0[0][0], s0[1][0]) > min(s1[0][0], s1[1][0])) and (min(s0[0][0], s0[1][0]) < max(s1[0][0], s1[1][0]))
    
    #Case 2: s0, s1 is nearly vertical
    if abs(1/gradient[0] - 1/gradient[1]) < a and abs(x_intercept[0] - x_intercept[1]) < c:
        return (max(s0[0][1], s0[1][1]) > min(s1[0][1], s1[1][1])) and (min(s0[0][1], s0[1][1]) < max(s1[0][1], s1[1][1]))
    
    #Case 3: s0, s1 are connected, we only consider the difference between two lines' gradients
    if np.all([np.any([s0[0]==s1[1], s0[1]==s1[0]]), np.any([(abs(gradient[0] - gradient[1])) < a, abs(1/gradient[0] - 1/gradient[1]) < a])]):
        return (max(s0[0][1], s0[1][1]) == max(s1[0][1], s1[1][1])) or (min(s0[0][1], s0[1][1]) == min(s1[0][1], s1[1][1]))


def intersects(s0,s1):

    dx = [s0[1][0]-s0[0][0], s1[1][0]-s1[0][0]]
    dy = [s0[1][1]-s0[0][1], s1[1][1]-s1[0][1]]
    det0 = dy[1]*(s1[1][0]-s0[0][0]) - dx[1]*(s1[1][1]-s0[0][1])
    det1 = dy[1]*(s1[1][0]-s0[1][0]) - dx[1]*(s1[1][1]-s0[1][1])
    det2 = dy[0]*(s0[1][0]-s1[0][0]) - dx[0]*(s0[1][1]-s1[0][1])
    det3 = dy[0]*(s0[1][0]-s1[1][0]) - dx[0]*(s0[1][1]-s1[1][1])

    return det0*det1 < 0 and det2*det3 < 0


def intersection_detection(G, pos, path):
    path = [0] + path + [0]
    new_path = []
    for i in range(len(path)-1):
        for j in range(i+1,len(path)-1):
            s0 = [pos[path[i]], pos[path[i+1]]]
            s1 = [pos[path[j]], pos[path[j+1]]]
            if intersects(s0,s1) == True:

                #make a swap and reverse the order of nodes between i+1 to j
                new_path = path[:i+1] + path[i+1:j+1][::-1] + path[j+1:]
                new_path.remove(0)
                new_path.remove(0)
                return new_path 

            elif collinear(s0,s1,a, b, c) == True:

                #if the swap increases the length, unswap them
                if i+1 == j and j < len(path)-2:
                    diff_l = 0 - G[path[i]][path[i+1]]['weight'] - G[path[j+1]][path[j+2]]['weight']+ G[path[i]][path[j+1]]['weight']+ G[path[j]][path[j+2]]['weight']
                    if diff_l < 0:
                        path[i+1], path[j+1] = path[j+1], path[i+1]
                        path.remove(0)
                        path.remove(0)
                        return path
                    
                else: 
                    diff_l = 0 - G[path[i]][path[i+1]]['weight'] - G[path[j+1]][path[j]]['weight'] + G[path[i]][path[j]]['weight']+G[path[j+1]][path[i+1]]['weight']
                    if diff_l < 0 :
                        new_path = path[:i+1] + path[i+1:j+1][::-1] + path[j+1:]
                        new_path.remove(0)
                        new_path.remove(0)
                        return new_path

    path.remove(0)
    path.remove(0)
    return path

def full_intersection_detection(G, pos, path, iterations, a = 0.01, b = 0.01, c = 0.01):
    n = G.number_of_nodes()
    new_path = intersection_detection(G, pos, path,a,b,c)
    i = 1
    while new_path != path and i < iterations:
        path = intersection_detection(G, pos, new_path,a,b,c)
        new_path = intersection_detection(G, pos, path,a,b,c)
        i += 2   
    return new_path, i 

def length(G, path):
    """
     G is a weighted connected graph, preferably with a small (<50) number of nodes.
     path is a list of n-1 city indexes (excluding fixed point 0)
     output: the total length of the path
    """
    n = G.number_of_nodes()
    distance = sum([G[path[i]][path[i+1]]['weight'] for i in range(n - 2)]) + G[path[-1]][0]['weight'] + G[path[0]][0]['weight']
    return distance

# step 1 : Initial solution 
# We will start with a short but not yet optimal solution which is easy to find. 
# Using the greedy approach, we start with node 0 and find the nearest node. 
# Each time find the nearest unvisited node from the current node until all the nodes are visited.
 
def greedy_path(G):
    
    #Input: G is a complete weighted undirected graph
    #Output: The greedy circular path starting in 0
    # 0 is not included in the output list
    
    #initialisation
    n = G.number_of_nodes()
    list_of_nodes = list(G.nodes())
    i = 0
    initial_solution = [0]
    
    while len(list_of_nodes) > 1:
        
        list_of_nodes.remove(i) # remove the node which is already in short_path
        k = list_of_nodes[0]
        minimum = G[i][k]['weight']

        # searching for the nearest node
        for j in list_of_nodes:
            if G[i][j]['weight'] < minimum:
                minimum = G[i][j]['weight']
                k = j
        i = k
        initial_solution += [i] # append the nearest node to short_path
    
    initial_solution.remove(0) # remove the initial node
    return initial_solution

def adjacency_matrix(path):
    """
    Input: 
    """
    n = len(path)+1
    F = np.zeros((n,n))
    F[0][path[0]] = 1
    F[path[-1]][0] = 1
    for i in range(n-2):
        F[path[i]][path[i+1]] = 1
    return F

def tabu_search(G, iterations = 10000, permutations = 10, p = 0.7):
    """
    Input: G is a complete weighted undirected graph
           iterations is the number of times we repeat the algorithm
           permutations is the number of random permutations we generate
           p is the probability of not entering the roulette
    Output: The shortest path, and the shortest distance found by the Tabu search
    """

    #Initialization of variables
    n = G.number_of_nodes()
    tabu = []
    edge_frequency_list = []
    short_path = greedy_path(G)    #initial solution
    short_distance = length(G, short_path)    #initial short distance

    # Choose parameters, should be a function of n
    tabu_list_length = 2 * math.floor(2/5*n) #only change things inside the floor function

    frequency_list_length = math.floor(2/5*n) #only change things inside the floor function

    # Choose penalty base parameter, should be a function of greedy_path(G) and frequency_list_length
    penalty_parameter = length(G, greedy_path(G)) /(20 * frequency_list_length)

    # Choose penalty base parameter, only change things inside the fllor function, should be a function of frequency_list_length
    penalty_limit = math.floor(3/4* frequency_list_length)

    # find the edge list
    A = adjacency_matrix(short_path)
    edge_frequency_list.append(A)

    best_path = short_path
    best_distance = short_distance

    node_pair = [(i, j) for i in range(n-2) for j in range(i+1, n-1)]

    # Beginning the iterations
    for t in range(iterations):

        #Initialization specific for this iteration.
        iteration_node_pair = []
        iteration_edge_frequency_list = []
        iteration_distances = []
        iteration_paths = []
        
        permutation_sample = rand.sample(node_pair, permutations)
        for pair in permutation_sample: 

            # inherit the edge frequency list
            iteration_edge_frequency_list = edge_frequency_list.copy()

            #Generating the random swap.
            i, j = pair

            #Creating a new path even if the elements are in the tabu list, and add to the edge frequency list.
            new_path = short_path.copy()
            new_path[i], new_path[j] = short_path[j], short_path[i]
            A = adjacency_matrix(new_path)
            iteration_edge_frequency_list.append(A)

            #Checking if the frequency list is too big; if it is, remove the first element and add the new one.
            if len(iteration_edge_frequency_list) > frequency_list_length:
                del iteration_edge_frequency_list[0]
            iteration_frequency_matrix = sum([x for x in iteration_edge_frequency_list])
            
            #Computing the weight of the new path.
            #NOTE: Depending on what proves to be efficient, we may change how the frequencies influence the distance.
            #For edges with frequency >= 3, add a penalty of 10 (3, 10 changable)

            new_distance = 0
            new_path = [0] + new_path + [0]

            for k in range(len(new_path)-1):
                new_distance += G[new_path[k]][new_path[k+1]]['weight']
                if iteration_frequency_matrix[new_path[k]][new_path[k+1]] >= penalty_limit:
                    new_distance += penalty_parameter * iteration_frequency_matrix[new_path[k]][new_path[k+1]]
                    """Change parameters later"""
            del new_path[-1]
            del new_path[0]
            
            #Checking for aspiration conditions and completes the iteration-specific lists.
            
            if (new_distance < short_distance and ([short_path[i], short_path[j]] in tabu) and tabu.index([short_path[i], short_path[j]]) < 2) \
               or ([short_path[i], short_path[j]] not in tabu):
                iteration_distances.append(new_distance)
                iteration_node_pair.append([short_path[i],short_path[j]])
                iteration_paths.append(new_path)
            del iteration_edge_frequency_list[-1]
                
        #Obtaining the final results based on the probabilities; if the random number generated is bigger than p,
        #we choose a non-optimal solution; if the random number generated is smaller, we choose the optimal one.
        coin_toss = rand.uniform(0,1)
        if coin_toss < p:
            short_distance = min(iteration_distances)
            index = iteration_distances.index(short_distance)
        # choose a roulette method if not
        else:
            roul = roulette(iteration_distances)
            short_distance = roul[0]
            index = roul[1]
        short_path = iteration_paths[index]
        tabu_pair = iteration_node_pair[index]
        reversed_tabu_pair = (tabu_pair[1], tabu_pair[0])
        tabu.append(tabu_pair)
        tabu.append(reversed_tabu_pair)

        #delete the first entry in tabu list and edge frequency list if they are too long
        if len(tabu) > tabu_list_length: # parameter can be changed
            del tabu[0:2]
        edge_frequency_list.append(adjacency_matrix(short_path))
        if len(edge_frequency_list) > frequency_list_length:
            del edge_frequency_list[0]

        true_distance = length(G,short_path)
        if true_distance < best_distance:
            best_path = short_path
            best_distance = true_distance

    return best_distance, best_path

def exact_solution(G):
        """
        Find the exact optimal solution for graph G.
        """
        n = G.number_of_nodes()
        shortest_distance = length(G, list(range(1, n)))
        for x in itertools.permutations(list(range(1, n))):
            distance = length(G, x)
            if distance < shortest_distance:
                global_min_path = x
                shortest_distance = distance
        return shortest_distance, global_min_path
